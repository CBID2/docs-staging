---
title:  Import CSV Files from Amazon S3 or GCS into TiDB Cloud
summary: Learn how to import CSV files from Amazon S3 or GCS into TiDB Cloud.
---

# Amazon S3 または GCS からTiDB Cloudに CSV ファイルをインポートする {#import-csv-files-from-amazon-s3-or-gcs-into-tidb-cloud}

このドキュメントでは、圧縮されていない CSV ファイルを Amazon Simple Storage Service (Amazon S3) または Google Cloud Storage (GCS) からTiDB Cloudにインポートする方法について説明します。

> **ノート：**
>
> -   CSV ソース ファイルが圧縮されている場合は、インポートする前にまずファイルを解凍する必要があります。
> -   データの一貫性を確保するために、 TiDB Cloudでは CSV ファイルを空のテーブルにのみインポートできます。既にデータが含まれている既存のテーブルにデータをインポートするには、このドキュメントに従って、 TiDB Cloudを使用してデータを一時的な空のテーブルにインポートし、 `INSERT SELECT`ステートメントを使用してデータをターゲットの既存のテーブルにコピーします。

## ステップ 1.CSV ファイルを準備する {#step-1-prepare-the-csv-files}

1.  CSV ファイルが 256 MB より大きい場合は、それぞれのサイズが約 256 MB の小さなファイルに分割することを検討してください。

    TiDB Cloudは、非常に大きな CSV ファイルのインポートをサポートしていますが、サイズが 256 MB 前後の複数の入力ファイルで最高のパフォーマンスを発揮します。これは、 TiDB Cloudが複数のファイルを並行して処理できるため、インポート速度が大幅に向上する可能性があるためです。

2.  次のように CSV ファイルに名前を付けます。

    -   CSV ファイルにテーブル全体のすべてのデータが含まれている場合は、ファイルに`${db_name}.${table_name}.csv`形式の名前を付けます。これは、データをインポートするときに`${db_name}.${table_name}`テーブルにマップされます。

    -   1 つのテーブルのデータが複数の CSV ファイルに分割されている場合は、これらの CSV ファイルに数値のサフィックスを追加します。たとえば、 `${db_name}.${table_name}.000001.csv`と`${db_name}.${table_name}.000002.csv`です。数値サフィックスは連続していなくてもかまいませんが、昇順でなければなりません。また、数字の前にゼロを追加して、すべてのサフィックスが同じ長さになるようにする必要もあります。

    > **ノート：**
    >
    > 上記のルールに従って CSV ファイル名を更新できない場合 (たとえば、CSV ファイルのリンクが他のプログラムでも使用されている場合など) は、ファイル名を変更せずに[ステップ 4](#step-4-import-csv-files-to-tidb-cloud)の**カスタム パターン**を使用してソース データをインポートできます。単一のターゲット テーブルに。

## ステップ 2. ターゲット表スキーマを作成する {#step-2-create-the-target-table-schemas}

CSV ファイルにはスキーマ情報が含まれていないため、CSV ファイルからTiDB Cloudにデータをインポートする前に、次のいずれかの方法を使用してテーブル スキーマを作成する必要があります。

-   方法 1: TiDB Cloudで、ソース データのターゲット データベースとテーブルを作成します。

-   方法 2: CSV ファイルが配置されている Amazon S3 または GCS ディレクトリで、ソース データのターゲット テーブル スキーマ ファイルを次のように作成します。

    1.  ソース データのデータベース スキーマ ファイルを作成します。

        CSV ファイルが[ステップ1](#step-1-prepare-the-csv-files)の命名規則に従っている場合、データベース スキーマ ファイルはデータ インポートのオプションです。それ以外の場合、データベース スキーマ ファイルは必須です。

        各データベース スキーマ ファイルは`${db_name}-schema-create.sql`形式で、 `CREATE DATABASE` DDL ステートメントを含む必要があります。このファイルを使用すると、 TiDB Cloudは、データをインポートするときにデータを格納するための`${db_name}`のデータベースを作成します。

        たとえば、次のステートメントを含む`mydb-scehma-create.sql`ファイルを作成すると、データをインポートするときにTiDB Cloudによって`mydb`データベースが作成されます。

        
        ```sql
        CREATE DATABASE mydb;
        ```

    2.  ソース データのテーブル スキーマ ファイルを作成します。

        CSV ファイルが配置されている Amazon S3 または GCS ディレクトリにテーブル スキーマ ファイルを含めない場合、データをインポートするときに、 TiDB Cloudは対応するテーブルを作成しません。

        各テーブル スキーマ ファイルは`${db_name}.${table_name}-schema.sql`形式で、 `CREATE TABLE` DDL ステートメントを含む必要があります。このファイルを使用すると、データをインポートすると、 TiDB Cloudは`${db_name}`データベースに`${db_table}`テーブルを作成します。

        たとえば、次のステートメントを含む`mydb.mytable-schema.sql`ファイルを作成すると、データをインポートすると、 TiDB Cloudは`mydb`データベースに`mytable`テーブルを作成します。

        
        ```sql
        CREATE TABLE mytable (
        ID INT,
        REGION VARCHAR(20),
        COUNT INT );
        ```

        > **ノート：**
        >
        > 各`${db_name}.${table_name}-schema.sql`ファイルには、単一の DDL ステートメントのみを含める必要があります。ファイルに複数の DDL ステートメントが含まれている場合、最初のステートメントのみが有効になります。

## ステップ 3. クロスアカウント アクセスを構成する {#step-3-configure-cross-account-access}

TiDB Cloudが Amazon S3 または GCS バケット内の CSV ファイルにアクセスできるようにするには、次のいずれかを実行します。

-   CSV ファイルが Amazon S3 にある場合は、 [Amazon S3 へのクロスアカウント アクセスを設定する](/tidb-cloud/config-s3-and-gcs-access.md#configure-amazon-s3-access) .

    完了したら、 [ステップ 4](#step-4-import-csv-files-to-tidb-cloud)で必要になるため、Role ARN の値を書き留めます。

-   CSV ファイルが GCS にある場合は、 [GCS へのクロスアカウント アクセスを構成する](/tidb-cloud/config-s3-and-gcs-access.md#configure-gcs-access) .

## ステップ 4.CSV ファイルをTiDB Cloudにインポートする {#step-4-import-csv-files-to-tidb-cloud}

CSV ファイルをTiDB Cloudにインポートするには、次の手順を実行します。

1.  [**クラスター]**ページに移動します。

2.  ターゲットクラスタの領域を見つけて、領域の右上隅にある [**データのインポート**] をクリックします。 [<strong>データ インポート タスク]</strong>ページが表示されます。

    > **ヒント：**
    >
    > または、[**クラスター**] ページでターゲットクラスタの名前をクリックし、右上隅にある [<strong>データのインポート</strong>] をクリックすることもできます。

3.  [**データ インポート タスク]**ページで、次の情報を指定します。

    -   **データ ソース タイプ**: データ ソースのタイプを選択します。

    -   **バケット URL** : CSV ファイルが配置されているバケット URL を選択します。

    -   **データ形式**: <strong>CSV</strong>を選択します。

    -   **資格情報の設定**(このフィールドは AWS S3 でのみ表示されます): <strong>Role-ARN</strong>の Role ARN 値を入力します。

    -   **CSVConfiguration / コンフィグレーション**: 区切り記号、区切り記号、ヘッダー、非 null、null、バックスラッシュ エスケープ、trim-last-separator など、CSV 固有の構成を確認して更新します。これらのフィールドのすぐ横に、各 CSV 構成の説明があります。

        > **ノート：**
        >
        > 区切り記号、区切り記号、およびヌルの構成では、英数字と特定の特殊文字の両方を使用できます。サポートされている特殊文字には、 `\t` 、 `\b` 、 `\n` 、 `\r` 、 `\f` 、および`\u0001`が含まれます。

    -   **ターゲット クラスタ**: <strong>[ユーザー名]</strong>および [<strong>パスワード</strong>] フィールドに入力します。

    -   **DB/Tables Filter** : インポートするテーブルをフィルタリングする場合は、このフィールドに`,`で区切られた 1 つ以上のテーブル フィルターを指定できます。

        例えば：

        -   `db01.*` : `db01`データベース内のすべてのテーブルがインポートされます。
        -   `db01.table01*,db01.table02*` : `db01`データベースの`table01`と`table02`で始まるすべてのテーブルがインポートされます。
        -   `!db02.*` : `db02`データベースのテーブルを除き、他のすべてのテーブルがインポートされます。 `!`は、インポートする必要のないテーブルを除外するために使用されます。
        -   `*.*` : すべてのテーブルがインポートされます。

        詳細については、 [テーブル フィルター snytax](/table-filter.md#syntax)を参照してください。

    -   **カスタム パターン**: ファイル名が特定のパターンに一致する CSV ファイルを単一のターゲット テーブルにインポートする場合は、<strong>カスタム パターン</strong>機能を有効にします。

        > **ノート：**
        >
        > この機能を有効にすると、1 つのインポート タスクで一度に 1 つのテーブルにのみデータをインポートできます。この機能を使用してデータを別のテーブルにインポートする場合は、インポートするたびに別のターゲット テーブルを指定して、複数回インポートする必要があります。

        **カスタム パターン**が有効になっている場合、次のフィールドで、CSV ファイルと単一のターゲット テーブルとの間のカスタム マッピング ルールを指定する必要があります。

        -   **オブジェクト名パターン**: インポートする CSV ファイルの名前と一致するパターンを入力します。 CSV ファイルが 1 つしかない場合は、ここにファイル名を直接入力できます。

            例えば：

            -   `my-data?.csv` : `my-data`と 1 文字 ( `my-data1.csv`と`my-data2.csv`など) で始まるすべての CSV ファイルが同じターゲット テーブルにインポートされます。
            -   `my-data*.csv` : `my-data`で始まるすべての CSV ファイルが同じターゲット テーブルにインポートされます。

        -   **ターゲット テーブル名**: TiDB Cloudのターゲット テーブルの名前を入力します。これは`${db_name}.${table_name}`形式である必要があります。たとえば、 `mydb.mytable`です。このフィールドは特定のテーブル名を 1 つしか受け付けないため、ワイルドカードはサポートされていないことに注意してください。

4.  [**インポート]**をクリックします。

    データベース リソースの消費に関する警告メッセージが表示されます。

5.  [**確認]**をクリックします。

    TiDB Cloudは、指定されたバケット URL のデータにアクセスできるかどうかの検証を開始します。検証が完了して成功すると、インポート タスクが自動的に開始されます。 `AccessDenied`エラーが発生した場合は、 [S3 からのデータ インポート中のアクセス拒否エラーのトラブルシューティング](/tidb-cloud/troubleshoot-import-access-denied-error.md)を参照してください。

6.  インポートの進行状況が成功を示したら、 **Total Files:**の後の数字を確認します。

    数値がゼロの場合は、[**オブジェクト名パターン]**フィールドに入力した値に一致するデータ ファイルがないことを意味します。この場合、[<strong>オブジェクト名パターン]</strong>フィールドにタイプミスがないことを確認してから、再試行してください。

インポート タスクの実行時に、サポートされていない変換または無効な変換が検出された場合、 TiDB Cloudはインポート ジョブを自動的に終了し、インポート エラーを報告します。

インポート エラーが発生した場合は、次の手順を実行します。

1.  部分的にインポートされたテーブルを削除します。
2.  テーブル スキーマ ファイルを確認してください。エラーがある場合は、テーブル スキーマ ファイルを修正します。
3.  CSV ファイルのデータ型を確認してください。
4.  インポート タスクを再試行します。
